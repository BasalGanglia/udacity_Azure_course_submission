{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: ilkkaamlws\n",
      "Azure region: northeurope\n",
      "Subscription id: 1f63a07e-5703-4d10-925f-b1c603594482\n",
      "Resource group: ilkka-aml\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.get(name=\"ilkkaamlws\")\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project-new\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "training_cluster = ComputeTarget.create(ws, \"minunudacluster2\", compute_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "from azureml.train.hyperdrive import choice\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "param_space = {\n",
    "                 '--C': choice(0.1, 0.3, 1),\n",
    "                 '--max_iter': choice(10, 20, 30, 100)\n",
    "              }\n",
    "ps = RandomParameterSampling(param_space)\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(slack_amount = 0.2, evaluation_interval=1)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "est = SKLearn(source_directory=\".\",\n",
    "              entry_script='train.py',\n",
    "             compute_target = training_cluster)\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(estimator=est,\n",
    "                                     hyperparameter_sampling=ps,\n",
    "                                     policy=policy,\n",
    "                                     primary_metric_name='Accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=5,\n",
    "                                     max_concurrent_runs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d410fd4deb485b91ac72c0dd40ec03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/minunudahyperi2/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4?wsid=/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourcegroups/ilkka-aml/workspaces/ilkkaamlws\", \"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"run_properties\": {\"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"created_utc\": \"2020-11-08T15:41:06.482997Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"90952633-f777-47df-92ed-98b48ea4aa73\", \"score\": \"0.9101723719349356\", \"best_child_run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"2\", \"max_concurrent_jobs\": \"2\", \"_aml_system_max_total_jobs\": \"5\", \"max_total_jobs\": \"5\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0, \\\"slack_amount\\\": 0.2}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0, \\\"slack_amount\\\": 0.2}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0.1, 0.3, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30, 100]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0.1, 0.3, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30, 100]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://northeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/minunudahyperi2\\\", \\\"SubscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"ResourceGroupName\\\": \\\"ilkka-aml\\\", \\\"WorkspaceName\\\": \\\"ilkkaamlws\\\", \\\"ExperimentName\\\": \\\"minunudahyperi2\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"minunudacluster2\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"sklearn:0.20.3-cpu\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": \\\"viennaprivate.azurecr.io\\\", \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"90952633-f777-47df-92ed-98b48ea4aa73\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"954c9218-0f04-4c8b-ba10-9fad255f83cf\\\", \\\"amlClientRequestId\\\": \\\"e0866ed8-4f34-4e7a-8ca2-050180ece3f8\\\", \\\"amlClientSessionId\\\": \\\"62946d35-4ad7-4e24-ba72-da1aa0f8003e\\\", \\\"subscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 5, \\\"maxConcurrentRuns\\\": 2, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://northeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/minunudahyperi2\\\", \\\"SubscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"ResourceGroupName\\\": \\\"ilkka-aml\\\", \\\"WorkspaceName\\\": \\\"ilkkaamlws\\\", \\\"ExperimentName\\\": \\\"minunudahyperi2\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"minunudacluster2\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"sklearn:0.20.3-cpu\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": \\\"viennaprivate.azurecr.io\\\", \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"90952633-f777-47df-92ed-98b48ea4aa73\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"954c9218-0f04-4c8b-ba10-9fad255f83cf\\\", \\\"amlClientRequestId\\\": \\\"e0866ed8-4f34-4e7a-8ca2-050180ece3f8\\\", \\\"amlClientSessionId\\\": \\\"62946d35-4ad7-4e24-ba72-da1aa0f8003e\\\", \\\"subscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 5, \\\"maxConcurrentRuns\\\": 2, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2020-11-08T15:41:07.337523\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-11-08T15:41:07.337523\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"db99c09a934fe3b8a72fd51d77e60828e6d126f294f5001fea5949a16a202728\\\"\", \"progress_metadata_digest\": \"\\\"db99c09a934fe3b8a72fd51d77e60828e6d126f294f5001fea5949a16a202728\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2020-11-08T15:41:07.337523\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-11-08T15:41:07.337523\\\"\", \"_aml_system_HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 30}\", \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 30}\", \"_aml_system_HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 10}\", \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 10}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_preparation\", \"prepare_run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_preparation\", \"_aml_system_HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 10}\", \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 10}\", \"_aml_system_HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 100}\", \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 100}\", \"_aml_system_HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 100}\", \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 100}\", \"_aml_system_final_best_metric_update_retry_count\": \"1\", \"final_best_metric_update_retry_count\": \"1\"}, \"end_time_utc\": \"2020-11-08T15:50:14.154116Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://ilkkaamlws0991200259.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=QzmH7mpigmDzmPIgfWl3BasPKOR4xOkadnZuYfuE7MQ%3D&st=2020-11-08T16%3A40%3A43Z&se=2020-11-09T00%3A50%3A43Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:09:07\", \"hyper_parameters\": {\"--C\": [\"choice\", [[0.1, 0.3, 1]]], \"--max_iter\": [\"choice\", [[10, 20, 30, 100]]]}}, \"child_runs\": [{\"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1\", \"run_number\": 38, \"metric\": 0.90653071, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-08T15:42:09.416905Z\", \"end_time\": \"2020-11-08T15:44:14.620919Z\", \"created_time\": \"2020-11-08T15:41:39.308424Z\", \"created_time_dt\": \"2020-11-08T15:41:39.308424Z\", \"duration\": \"0:02:35\", \"hyperdrive_id\": \"71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"arguments\": null, \"param_--C\": 1, \"param_--max_iter\": 10, \"best_metric\": 0.90653071}, {\"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0\", \"run_number\": 39, \"metric\": 0.90531682, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-08T15:42:17.827734Z\", \"end_time\": \"2020-11-08T15:44:29.778892Z\", \"created_time\": \"2020-11-08T15:41:39.392142Z\", \"created_time_dt\": \"2020-11-08T15:41:39.392142Z\", \"duration\": \"0:02:50\", \"hyperdrive_id\": \"71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"arguments\": null, \"param_--C\": 1, \"param_--max_iter\": 30, \"best_metric\": 0.90653071}, {\"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2\", \"run_number\": 40, \"metric\": 0.89779073, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-08T15:45:13.470858Z\", \"end_time\": \"2020-11-08T15:46:29.738698Z\", \"created_time\": \"2020-11-08T15:44:43.35177Z\", \"created_time_dt\": \"2020-11-08T15:44:43.35177Z\", \"duration\": \"0:01:46\", \"hyperdrive_id\": \"71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"arguments\": null, \"param_--C\": 0.1, \"param_--max_iter\": 10, \"best_metric\": 0.90653071}, {\"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3\", \"run_number\": 41, \"metric\": 0.90386016, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-08T15:45:27.350607Z\", \"end_time\": \"2020-11-08T15:46:42.353415Z\", \"created_time\": \"2020-11-08T15:44:43.436035Z\", \"created_time_dt\": \"2020-11-08T15:44:43.436035Z\", \"duration\": \"0:01:58\", \"hyperdrive_id\": \"71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"arguments\": null, \"param_--C\": 0.1, \"param_--max_iter\": 100, \"best_metric\": 0.90653071}, {\"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4\", \"run_number\": 42, \"metric\": 0.91017237, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-08T15:47:47.407064Z\", \"end_time\": \"2020-11-08T15:49:04.441887Z\", \"created_time\": \"2020-11-08T15:47:16.507925Z\", \"created_time_dt\": \"2020-11-08T15:47:16.507925Z\", \"duration\": \"0:01:47\", \"hyperdrive_id\": \"71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"arguments\": null, \"param_--C\": 1, \"param_--max_iter\": 100, \"best_metric\": 0.91017237}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Regularization Strength:\": [{\"categories\": [38, 39, 40, 41, 42], \"mode\": \"markers\", \"name\": \"Regularization Strength:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [1.0, 1.0, 0.1, 0.1, 1.0]}, {\"categories\": [38, 39, 40, 41, 42], \"mode\": \"lines\", \"name\": \"Regularization Strength:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [1.0, 1.0, 1.0, 1.0, 1.0]}], \"Max iterations:\": [{\"categories\": [38, 39, 40, 41, 42], \"mode\": \"markers\", \"name\": \"Max iterations:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [10, 30, 10, 100, 100]}, {\"categories\": [38, 39, 40, 41, 42], \"mode\": \"lines\", \"name\": \"Max iterations:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [10, 30, 30, 100, 100]}], \"Accuracy\": [{\"categories\": [38, 39, 40, 41, 42], \"mode\": \"markers\", \"name\": \"Accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9065307113377034, 0.9053168244719592, 0.8977907259043457, 0.9038601602330663, 0.9101723719349356]}, {\"categories\": [38, 39, 40, 41, 42], \"mode\": \"lines\", \"name\": \"Accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9065307113377034, 0.9065307113377034, 0.9065307113377034, 0.9065307113377034, 0.9101723719349356]}]}, \"metricName\": null, \"primaryMetricName\": \"Accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": [\"Accuracy\", \"Accuracy\", \"Accuracy\"], \"timestamp\": [\"2020-11-08 15:44:47.917808+00:00\", \"2020-11-08 15:49:37.285715+00:00\", \"2020-11-08 15:49:37.285715+00:00\"], \"run_id\": [\"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1\", \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4\", \"HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4\"], \"metric_value\": [0.9065307113377034, 0.9101723719349356, 0.9101723719349356], \"final\": [false, false, true]}]}]}], \"run_logs\": \"[2020-11-08T15:41:06.835669][API][INFO]Experiment created\\r\\n[2020-11-08T15:41:07.730918][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2020-11-08T15:41:07.8537858Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2020-11-08T15:41:07.912081][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2020-11-08T15:41:38.5270648Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2020-11-08T15:41:38.5358590Z][SCHEDULER][INFO]Scheduling job, id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0'\\r\\n[2020-11-08T15:41:38.5376810Z][SCHEDULER][INFO]Scheduling job, id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1'\\r\\n[2020-11-08T15:41:39.4665139Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1'\\r\\n[2020-11-08T15:41:39.5793236Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0'\\r\\n[2020-11-08T15:42:10.551453][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:42:41.555642][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:43:11.968058][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:43:42.680603][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:44:13.389547][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:44:42.039581][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2020-11-08T15:44:42.262684][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2020-11-08T15:44:42.6746823Z][SCHEDULER][INFO]Scheduling job, id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2'\\r\\n[2020-11-08T15:44:42.6760035Z][SCHEDULER][INFO]Scheduling job, id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3'\\r\\n[2020-11-08T15:44:43.5125309Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2'\\r\\n[2020-11-08T15:44:43.6074903Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3'\\r\\n[2020-11-08T15:45:14.243834][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:45:45.700727][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:46:16.503713][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:46:46.344659][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2020-11-08T15:46:46.564618][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2020-11-08T15:47:15.7870785Z][SCHEDULER][INFO]Scheduling job, id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4'\\r\\n[2020-11-08T15:47:16.6589256Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4'\\r\\n[2020-11-08T15:47:17.171553][GENERATOR][INFO]Max number of jobs '5' reached for experiment.\\r\\n[2020-11-08T15:47:17.532398][GENERATOR][INFO]All jobs generated.\\r\\n[2020-11-08T15:47:48.532257][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:48:19.159225][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:48:50.104880][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-08T15:50:14.519481][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.16.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4',\n",
       " 'target': 'minunudacluster2',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-11-08T15:41:06.563577Z',\n",
       " 'endTimeUtc': '2020-11-08T15:50:14.154116Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"Accuracy\", \"goal\": \"maximize\"}',\n",
       "  'resume_from': 'null',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive',\n",
       "  'platform': 'AML',\n",
       "  'ContentSnapshotId': '90952633-f777-47df-92ed-98b48ea4aa73',\n",
       "  'score': '0.9101723719349356',\n",
       "  'best_child_run_id': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4',\n",
       "  'best_metric_status': 'Succeeded'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://ilkkaamlws0991200259.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=7to7P14gWXTdsJW1uWDo0YhmebxEocw7sOHlIaGjPyc%3D&st=2020-11-08T15%3A40%3A33Z&se=2020-11-08T23%3A50%3A33Z&sp=r'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "experiment = Experiment(workspace=ws, name ='minunudahyperi2')\n",
    "run = experiment.submit(config=hyperdrive_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_4', 'hyperparameters': '{\"--C\": 1, \"--max_iter\": 100}', 'best_primary_metric': 0.9101723719349356, 'status': 'Completed'}\n",
      "{'run_id': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_1', 'hyperparameters': '{\"--C\": 1, \"--max_iter\": 10}', 'best_primary_metric': 0.9065307113377034, 'status': 'Completed'}\n",
      "{'run_id': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_0', 'hyperparameters': '{\"--C\": 1, \"--max_iter\": 30}', 'best_primary_metric': 0.9053168244719592, 'status': 'Completed'}\n",
      "{'run_id': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_3', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 100}', 'best_primary_metric': 0.9038601602330663, 'status': 'Completed'}\n",
      "{'run_id': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_2', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 10}', 'best_primary_metric': 0.8977907259043457, 'status': 'Completed'}\n",
      "{'run_id': 'HD_71b91abf-23fa-4626-bf2a-e46d3b99d2b4_preparation', 'hyperparameters': None, 'best_primary_metric': None, 'status': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "for child_run in run.get_children_sorted_by_primary_metric():\n",
    "    print(child_run)\n",
    "    \n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "#joblib.dump(best_run, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "### YOUR CODE HERE ###\n",
    "ds = TabularDatasetFactory.from_delimited_files(\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def clean_data(data):\n",
    "    # Dict for cleaning data\n",
    "    months = {\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}\n",
    "    weekdays = {\"mon\":1, \"tue\":2, \"wed\":3, \"thu\":4, \"fri\":5, \"sat\":6, \"sun\":7}\n",
    "\n",
    "    # Clean and one hot encode data\n",
    "    x_df = data.to_pandas_dataframe().dropna()\n",
    "    jobs = pd.get_dummies(x_df.job, prefix=\"job\")\n",
    "    x_df.drop(\"job\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(jobs)\n",
    "    \n",
    "    x_df[\"marital\"] = x_df.marital.apply(lambda s: 1 if s == \"married\" else 0)\n",
    "    x_df[\"default\"] = x_df.default.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"housing\"] = x_df.housing.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"loan\"] = x_df.loan.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    contact = pd.get_dummies(x_df.contact, prefix=\"contact\")\n",
    "    x_df.drop(\"contact\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(contact)\n",
    "    education = pd.get_dummies(x_df.education, prefix=\"education\")\n",
    "    x_df.drop(\"education\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(education)\n",
    "    x_df[\"month\"] = x_df.month.map(months)\n",
    "    x_df[\"day_of_week\"] = x_df.day_of_week.map(weekdays)\n",
    "    x_df[\"poutcome\"] = x_df.poutcome.apply(lambda s: 1 if s == \"success\" else 0)\n",
    "\n",
    "    #y_df = x_df.pop(\"y\").apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    return x_df\n",
    "    #return x_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# tryin to import this causes some weird ipykernel error...\n",
    "#from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "#x, y = clean_data(ds)\n",
    "# It makes no sense to split it to x and y in the clean data...\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cleaned_df = clean_data(ds)\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>...</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>education_basic.4y</th>\n",
       "      <th>education_basic.6y</th>\n",
       "      <th>education_basic.9y</th>\n",
       "      <th>education_high.school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional.course</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>education_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>355</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  marital  default  housing  loan  month  day_of_week  duration  \\\n",
       "0   57        1        0        0     1      5            1       371   \n",
       "1   55        1        0        1     0      5            4       285   \n",
       "2   33        1        0        0     0      5            5        52   \n",
       "3   36        1        0        0     0      6            5       355   \n",
       "4   27        1        0        1     0      7            5       189   \n",
       "\n",
       "   campaign  pdays  ...  contact_cellular  contact_telephone  \\\n",
       "0         1    999  ...                 1                  0   \n",
       "1         2    999  ...                 0                  1   \n",
       "2         1    999  ...                 1                  0   \n",
       "3         4    999  ...                 0                  1   \n",
       "4         2    999  ...                 1                  0   \n",
       "\n",
       "   education_basic.4y  education_basic.6y  education_basic.9y  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   1   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   education_high.school  education_illiterate education_professional.course  \\\n",
       "0                      1                     0                             0   \n",
       "1                      0                     0                             0   \n",
       "2                      0                     0                             0   \n",
       "3                      1                     0                             0   \n",
       "4                      1                     0                             0   \n",
       "\n",
       "   education_university.degree  education_unknown  \n",
       "0                            0                  0  \n",
       "1                            0                  1  \n",
       "2                            0                  0  \n",
       "3                            0                  0  \n",
       "4                            0                  0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "\n",
    "# nowhere in the course I saw any instructions on what to fill in here so I'll\n",
    "# follow the microsoft documentation... I'm not should I use accuracy here as a metric or not\n",
    "\n",
    "# In the project instructions on 5. automl run it says to \"split data into train and valid tests\"\n",
    "# so I do that even though I would like to let the automl do its on cross-validation which\n",
    "# seems like a better idea\n",
    "\n",
    "# Note on the above, I can\\t even use the crossvalidation if I split the data\n",
    "# myself, yet another mistake in the project instructions. Anyway, I'll skip\n",
    "# splitting the data myself then...\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data= cleaned_df,\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your automl run\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "#from azureml.core.experiment import Experiment\n",
    "# This would run on the local machine:\n",
    "#automl_experiment = Experiment(ws, 'automl_experiment2')\n",
    "#automl_run = automl_experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "# best_run, fitted_model = automl_run.get_output()\n",
    "# best_run_metrics = best_run.get_metrics()\n",
    "# for metric_name in best_run_metrics:\n",
    "#     metric = best_run_metrics[metric_name]\n",
    "#     print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_ds = TabularDatasetFactory.get_by_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for ds_name in ws.datastores:\n",
    "#    print(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_dataset = Dataset.Tabular.from_delimited_files(path=(default_ds,'training_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./training_data.csv\n",
      "Uploaded ./training_data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_8fd9393a8eaa4f64947d702e8dc7948e"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload_files(files=['./training_data.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='training-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "blob_ds = ws.get_default_datastore()\n",
    "csv_paths = [(blob_ds, './training-data/training_data.csv')]\n",
    "tab_ds = Dataset.Tabular.from_delimited_files(path=csv_paths)\n",
    "tab_ds = tab_ds.register(workspace=ws, name='csv_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also running in the cloud compute target in case that was a requirement\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data= tab_ds,\n",
    "    compute_target = training_cluster,\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote.\n"
     ]
    }
   ],
   "source": [
    "automl_experiment = Experiment(ws, 'automl_experiment4')\n",
    "automl_run = automl_experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score_weighted 0.9138264780226895\n",
      "log_loss 0.2031508708281234\n",
      "precision_score_micro 0.9160849772382398\n",
      "norm_macro_recall 0.5502518131383984\n",
      "recall_score_micro 0.9160849772382398\n",
      "f1_score_micro 0.9160849772382398\n",
      "accuracy 0.9160849772382398\n",
      "average_precision_score_micro 0.9801973224594749\n",
      "balanced_accuracy 0.7751259065691992\n",
      "AUC_macro 0.9445533304045678\n",
      "precision_score_macro 0.7916713493145954\n",
      "recall_score_weighted 0.9160849772382398\n",
      "f1_score_weighted 0.9148654627090704\n",
      "average_precision_score_weighted 0.9536722247052882\n",
      "AUC_weighted 0.9445533304045678\n",
      "f1_score_macro 0.7830498061646453\n",
      "AUC_micro 0.979389674427387\n",
      "recall_score_macro 0.7751259065691992\n",
      "average_precision_score_macro 0.8185365989416591\n",
      "matthews_correlation 0.5665539934794288\n",
      "weighted_accuracy 0.9511026951355795\n",
      "confusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_923a1931-69de-4491-bb73-5a63b7f5a617_29/confusion_matrix\n",
      "accuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_923a1931-69de-4491-bb73-5a63b7f5a617_29/accuracy_table\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "best_run, fitted_model = automl_run.get_output()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = automl_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Run(Experiment: automl_experiment4,\n",
       " Id: AutoML_923a1931-69de-4491-bb73-5a63b7f5a617_29,\n",
       " Type: azureml.scriptrun,\n",
       " Status: Completed),\n",
       " PipelineWithYTransformations(Pipeline={'memory': None,\n",
       "                                        'steps': [('datatransformer',\n",
       "                                                   DataTransformer(enable_dnn=None,\n",
       "                                                                   enable_feature_sweeping=None,\n",
       "                                                                   feature_sweeping_config=None,\n",
       "                                                                   feature_sweeping_timeout=None,\n",
       "                                                                   featurization_config=None,\n",
       "                                                                   force_text_dnn=None,\n",
       "                                                                   is_cross_validation=None,\n",
       "                                                                   is_onnx_compatible=None,\n",
       "                                                                   logger=None,\n",
       "                                                                   observer=None,\n",
       "                                                                   task=None,\n",
       "                                                                   working_dir=None))...\n",
       "                                                                                                                                    max_iter=1000,\n",
       "                                                                                                                                    n_jobs=1,\n",
       "                                                                                                                                    penalty='none',\n",
       "                                                                                                                                    power_t=0,\n",
       "                                                                                                                                    random_state=None,\n",
       "                                                                                                                                    tol=0.01))],\n",
       "                                                                                                       verbose=False))],\n",
       "                                                                                 flatten_transform=None,\n",
       "                                                                                 weights=[0.26666666666666666,\n",
       "                                                                                          0.26666666666666666,\n",
       "                                                                                          0.06666666666666667,\n",
       "                                                                                          0.06666666666666667,\n",
       "                                                                                          0.13333333333333333,\n",
       "                                                                                          0.06666666666666667,\n",
       "                                                                                          0.06666666666666667,\n",
       "                                                                                          0.06666666666666667]))],\n",
       "                                        'verbose': False},\n",
       "                              y_transformer={},\n",
       "                              y_transformer_name='LabelEncoder'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_cluster.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
