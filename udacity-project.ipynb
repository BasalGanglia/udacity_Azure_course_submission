{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: ilkkaamlws\n",
      "Azure region: northeurope\n",
      "Subscription id: 1f63a07e-5703-4d10-925f-b1c603594482\n",
      "Resource group: ilkka-aml\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.get(name=\"ilkkaamlws\")\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project-new\")\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "training_cluster = ComputeTarget.create(ws, \"minunudacluster2\", compute_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1598275789986
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "from azureml.train.hyperdrive import choice\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "param_space = {\n",
    "                 '--C': choice(0.1, 0.3, 1),\n",
    "                 '--max_iter': choice(10, 20, 30, 100)\n",
    "              }\n",
    "ps = RandomParameterSampling(param_space)\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(slack_amount = 0.2, evaluation_interval=1)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "est = SKLearn(source_directory=\".\",\n",
    "              entry_script='train.py',\n",
    "             compute_target = training_cluster)\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(estimator=est,\n",
    "                                     hyperparameter_sampling=ps,\n",
    "                                     policy=policy,\n",
    "                                     primary_metric_name='Accuracy',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                     max_total_runs=5,\n",
    "                                     max_concurrent_runs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46259720f7a74d3f999e62284e5d1abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/minunudahyperi2/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797?wsid=/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourcegroups/ilkka-aml/workspaces/ilkkaamlws\", \"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"run_properties\": {\"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"created_utc\": \"2020-11-06T09:59:16.174588Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"4fa74c66-c122-4097-932d-44c4cfdeefe0\", \"score\": \"0.9087157076960427\", \"best_child_run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2\", \"best_metric_status\": \"Succeeded\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"2\", \"max_concurrent_jobs\": \"2\", \"_aml_system_max_total_jobs\": \"5\", \"max_total_jobs\": \"5\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0, \\\"slack_amount\\\": 0.2}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0, \\\"slack_amount\\\": 0.2}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0.1, 0.3, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30, 100]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0.1, 0.3, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[10, 20, 30, 100]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://northeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/minunudahyperi2\\\", \\\"SubscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"ResourceGroupName\\\": \\\"ilkka-aml\\\", \\\"WorkspaceName\\\": \\\"ilkkaamlws\\\", \\\"ExperimentName\\\": \\\"minunudahyperi2\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"minunudacluster2\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"sklearn:0.20.3-cpu\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": \\\"viennaprivate.azurecr.io\\\", \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"4fa74c66-c122-4097-932d-44c4cfdeefe0\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"954c9218-0f04-4c8b-ba10-9fad255f83cf\\\", \\\"amlClientRequestId\\\": \\\"d72df5c0-ded7-4615-8c85-4eedfe6b5a18\\\", \\\"amlClientSessionId\\\": \\\"0f36619f-e2bd-40ba-b5bf-4340be72befa\\\", \\\"subscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 5, \\\"maxConcurrentRuns\\\": 2, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://northeurope.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/minunudahyperi2\\\", \\\"SubscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"ResourceGroupName\\\": \\\"ilkka-aml\\\", \\\"WorkspaceName\\\": \\\"ilkkaamlws\\\", \\\"ExperimentName\\\": \\\"minunudahyperi2\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"minunudacluster2\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": true, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"sklearn:0.20.3-cpu\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": \\\"viennaprivate.azurecr.io\\\", \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"4fa74c66-c122-4097-932d-44c4cfdeefe0\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"954c9218-0f04-4c8b-ba10-9fad255f83cf\\\", \\\"amlClientRequestId\\\": \\\"d72df5c0-ded7-4615-8c85-4eedfe6b5a18\\\", \\\"amlClientSessionId\\\": \\\"0f36619f-e2bd-40ba-b5bf-4340be72befa\\\", \\\"subscriptionId\\\": \\\"1f63a07e-5703-4d10-925f-b1c603594482\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 5, \\\"maxConcurrentRuns\\\": 2, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2020-11-06T09:59:17.496244\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2020-11-06T09:59:17.496244\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"5f5647886420b9902542e9f20b6f5eca86c47849ecccd4d3f377f49acdc902fa\\\"\", \"progress_metadata_digest\": \"\\\"5f5647886420b9902542e9f20b6f5eca86c47849ecccd4d3f377f49acdc902fa\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2020-11-06T09:59:17.496244\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2020-11-06T09:59:17.496244\\\"\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_preparation\", \"prepare_run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_preparation\", \"_aml_system_HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0\": \"{\\\"--C\\\": 0.3, \\\"--max_iter\\\": 30}\", \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0\": \"{\\\"--C\\\": 0.3, \\\"--max_iter\\\": 30}\", \"_aml_system_HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 10}\", \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 10}\", \"_aml_system_HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 100}\", \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 100}\", \"_aml_system_HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 100}\", \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3\": \"{\\\"--C\\\": 1, \\\"--max_iter\\\": 100}\", \"_aml_system_HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 20}\", \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 20}\", \"_aml_system_final_best_metric_update_retry_count\": \"1\", \"final_best_metric_update_retry_count\": \"1\"}, \"end_time_utc\": \"2020-11-06T10:09:01.418581Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://ilkkaamlws0991200259.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=oMY%2BddEQCzhdidkaLbX9G1GvylhoRSJIsK06XQROOeA%3D&st=2020-11-06T09%3A59%3A09Z&se=2020-11-06T18%3A09%3A09Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:09:45\", \"hyper_parameters\": {\"--C\": [\"choice\", [[0.1, 0.3, 1]]], \"--max_iter\": [\"choice\", [[10, 20, 30, 100]]]}}, \"child_runs\": [{\"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0\", \"run_number\": 24, \"metric\": 0.90738043, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-06T10:02:41.740891Z\", \"end_time\": \"2020-11-06T10:05:12.463215Z\", \"created_time\": \"2020-11-06T09:59:49.22411Z\", \"created_time_dt\": \"2020-11-06T09:59:49.22411Z\", \"duration\": \"0:05:23\", \"hyperdrive_id\": \"c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"arguments\": null, \"param_--C\": 0.3, \"param_--max_iter\": 30, \"best_metric\": 0.90738043}, {\"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1\", \"run_number\": 25, \"metric\": 0.90386016, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-06T10:02:43.195481Z\", \"end_time\": \"2020-11-06T10:04:54.222142Z\", \"created_time\": \"2020-11-06T09:59:49.744046Z\", \"created_time_dt\": \"2020-11-06T09:59:49.744046Z\", \"duration\": \"0:05:04\", \"hyperdrive_id\": \"c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"arguments\": null, \"param_--C\": 1, \"param_--max_iter\": 10, \"best_metric\": 0.90738043}, {\"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2\", \"run_number\": 26, \"metric\": 0.90871571, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-06T10:05:35.06748Z\", \"end_time\": \"2020-11-06T10:06:41.171348Z\", \"created_time\": \"2020-11-06T10:05:25.432275Z\", \"created_time_dt\": \"2020-11-06T10:05:25.432275Z\", \"duration\": \"0:01:15\", \"hyperdrive_id\": \"c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"arguments\": null, \"param_--C\": 0.1, \"param_--max_iter\": 100, \"best_metric\": 0.90871571}, {\"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3\", \"run_number\": 27, \"metric\": 0.90458849, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-06T10:05:35.07649Z\", \"end_time\": \"2020-11-06T10:06:37.678618Z\", \"created_time\": \"2020-11-06T10:05:25.460624Z\", \"created_time_dt\": \"2020-11-06T10:05:25.460624Z\", \"duration\": \"0:01:12\", \"hyperdrive_id\": \"c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"arguments\": null, \"param_--C\": 1, \"param_--max_iter\": 100, \"best_metric\": 0.90871571}, {\"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4\", \"run_number\": 28, \"metric\": 0.9077446, \"status\": \"Completed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2020-11-06T10:07:08.128721Z\", \"end_time\": \"2020-11-06T10:08:14.938451Z\", \"created_time\": \"2020-11-06T10:06:57.570053Z\", \"created_time_dt\": \"2020-11-06T10:06:57.570053Z\", \"duration\": \"0:01:17\", \"hyperdrive_id\": \"c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"arguments\": null, \"param_--C\": 0.1, \"param_--max_iter\": 20, \"best_metric\": 0.90871571}], \"children_metrics\": {\"categories\": [0], \"series\": {\"Regularization Strength:\": [{\"categories\": [24, 25, 26, 27, 28], \"mode\": \"markers\", \"name\": \"Regularization Strength:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.3, 1.0, 0.1, 1.0, 0.1]}, {\"categories\": [24, 25, 26, 27, 28], \"mode\": \"lines\", \"name\": \"Regularization Strength:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.3, 1.0, 1.0, 1.0, 1.0]}], \"Max iterations:\": [{\"categories\": [24, 25, 26, 27, 28], \"mode\": \"markers\", \"name\": \"Max iterations:\", \"stepped\": false, \"type\": \"scatter\", \"data\": [30, 10, 100, 100, 20]}, {\"categories\": [24, 25, 26, 27, 28], \"mode\": \"lines\", \"name\": \"Max iterations:_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [30, 30, 100, 100, 100]}], \"Accuracy\": [{\"categories\": [24, 25, 26, 27, 28], \"mode\": \"markers\", \"name\": \"Accuracy\", \"stepped\": false, \"type\": \"scatter\", \"data\": [0.9073804321437242, 0.9038601602330663, 0.9087157076960427, 0.9045884923525127, 0.9077445982034474]}, {\"categories\": [24, 25, 26, 27, 28], \"mode\": \"lines\", \"name\": \"Accuracy_max\", \"stepped\": true, \"type\": \"scatter\", \"data\": [0.9073804321437242, 0.9073804321437242, 0.9087157076960427, 0.9087157076960427, 0.9087157076960427]}]}, \"metricName\": null, \"primaryMetricName\": \"Accuracy\", \"showLegend\": false}, \"run_metrics\": [{\"name\": \"best_child_by_primary_metric\", \"run_id\": \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797\", \"categories\": [0], \"series\": [{\"data\": [{\"metric_name\": [\"Accuracy\", \"Accuracy\", \"Accuracy\"], \"timestamp\": [\"2020-11-06 10:05:20.016008+00:00\", \"2020-11-06 10:06:54.084650+00:00\", \"2020-11-06 10:06:54.084650+00:00\"], \"run_id\": [\"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0\", \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2\", \"HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2\"], \"metric_value\": [0.9073804321437242, 0.9087157076960427, 0.9087157076960427], \"final\": [false, false, true]}]}]}], \"run_logs\": \"[2020-11-06T09:59:16.773334][API][INFO]Experiment created\\r\\n[2020-11-06T09:59:17.7465704Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2020-11-06T09:59:17.786845][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2020-11-06T09:59:18.114857][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2020-11-06T09:59:48.3341024Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2020-11-06T09:59:48.3362060Z][SCHEDULER][INFO]Scheduling job, id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1'\\r\\n[2020-11-06T09:59:48.3348305Z][SCHEDULER][INFO]Scheduling job, id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0'\\r\\n[2020-11-06T09:59:49.3569075Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0'\\r\\n[2020-11-06T09:59:50.0939690Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1'\\r\\n[2020-11-06T10:02:47.855153][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:03:18.074248][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:03:48.193855][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:04:19.382424][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:04:50.054006][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:05:23.880637][GENERATOR][INFO]Trying to sample '2' jobs from the hyperparameter space\\r\\n[2020-11-06T10:05:24.051264][GENERATOR][INFO]Successfully sampled '2' jobs, they will soon be submitted to the execution target.\\r\\n[2020-11-06T10:05:24.7640131Z][SCHEDULER][INFO]Scheduling job, id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2'\\r\\n[2020-11-06T10:05:24.7655504Z][SCHEDULER][INFO]Scheduling job, id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3'\\r\\n[2020-11-06T10:05:25.5400833Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2'\\r\\n[2020-11-06T10:05:25.8192857Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3'\\r\\n[2020-11-06T10:05:51.296043][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:06:22.033238][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2, https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:06:55.049055][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2020-11-06T10:06:55.279357][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2020-11-06T10:06:56.9519062Z][SCHEDULER][INFO]Scheduling job, id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4'\\r\\n[2020-11-06T10:06:57.7247288Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4'\\r\\n[2020-11-06T10:07:22.322096][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:07:26.125703][GENERATOR][INFO]Max number of jobs '5' reached for experiment.\\r\\n[2020-11-06T10:07:26.486971][GENERATOR][INFO]All jobs generated.\\r\\n[2020-11-06T10:07:53.392103][ENFORCER][INFO]Jobs [https://northeurope.experiments.azureml.net/subscriptions/1f63a07e-5703-4d10-925f-b1c603594482/resourceGroups/ilkka-aml/providers/Microsoft.MachineLearningServices/workspaces/ilkkaamlws/experiments/**SCRUBBED**/runs/HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2020-11-06T10:09:01.620912][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.FINISHED'.\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.16.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797',\n",
       " 'target': 'minunudacluster2',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-11-06T09:59:16.231682Z',\n",
       " 'endTimeUtc': '2020-11-06T10:09:01.418581Z',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"Accuracy\", \"goal\": \"maximize\"}',\n",
       "  'resume_from': 'null',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive',\n",
       "  'platform': 'AML',\n",
       "  'ContentSnapshotId': '4fa74c66-c122-4097-932d-44c4cfdeefe0',\n",
       "  'score': '0.9087157076960427',\n",
       "  'best_child_run_id': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2',\n",
       "  'best_metric_status': 'Succeeded'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://ilkkaamlws0991200259.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=oMY%2BddEQCzhdidkaLbX9G1GvylhoRSJIsK06XQROOeA%3D&st=2020-11-06T09%3A59%3A09Z&se=2020-11-06T18%3A09%3A09Z&sp=r'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "experiment = Experiment(workspace=ws, name ='minunudahyperi2')\n",
    "run = experiment.submit(config=hyperdrive_config)\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1598276310862
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'run_id': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_2', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 100}', 'best_primary_metric': 0.9087157076960427, 'status': 'Completed'}\n",
      "{'run_id': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_4', 'hyperparameters': '{\"--C\": 0.1, \"--max_iter\": 20}', 'best_primary_metric': 0.9077445982034474, 'status': 'Completed'}\n",
      "{'run_id': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_0', 'hyperparameters': '{\"--C\": 0.3, \"--max_iter\": 30}', 'best_primary_metric': 0.9073804321437242, 'status': 'Completed'}\n",
      "{'run_id': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_3', 'hyperparameters': '{\"--C\": 1, \"--max_iter\": 100}', 'best_primary_metric': 0.9045884923525127, 'status': 'Completed'}\n",
      "{'run_id': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_1', 'hyperparameters': '{\"--C\": 1, \"--max_iter\": 10}', 'best_primary_metric': 0.9038601602330663, 'status': 'Completed'}\n",
      "{'run_id': 'HD_c8789b19-6b5f-4cbf-a65d-a0d21c92a797_preparation', 'hyperparameters': None, 'best_primary_metric': None, 'status': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "# Get your best run and save the model from that run.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "for child_run in run.get_children_sorted_by_primary_metric():\n",
    "    print(child_run)\n",
    "    \n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "#joblib.dump(best_run, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "### YOUR CODE HERE ###\n",
    "ds = TabularDatasetFactory.from_delimited_files(\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def clean_data(data):\n",
    "    # Dict for cleaning data\n",
    "    months = {\"jan\":1, \"feb\":2, \"mar\":3, \"apr\":4, \"may\":5, \"jun\":6, \"jul\":7, \"aug\":8, \"sep\":9, \"oct\":10, \"nov\":11, \"dec\":12}\n",
    "    weekdays = {\"mon\":1, \"tue\":2, \"wed\":3, \"thu\":4, \"fri\":5, \"sat\":6, \"sun\":7}\n",
    "\n",
    "    # Clean and one hot encode data\n",
    "    x_df = data.to_pandas_dataframe().dropna()\n",
    "    jobs = pd.get_dummies(x_df.job, prefix=\"job\")\n",
    "    x_df.drop(\"job\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(jobs)\n",
    "    \n",
    "    x_df[\"marital\"] = x_df.marital.apply(lambda s: 1 if s == \"married\" else 0)\n",
    "    x_df[\"default\"] = x_df.default.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"housing\"] = x_df.housing.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    x_df[\"loan\"] = x_df.loan.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    contact = pd.get_dummies(x_df.contact, prefix=\"contact\")\n",
    "    x_df.drop(\"contact\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(contact)\n",
    "    education = pd.get_dummies(x_df.education, prefix=\"education\")\n",
    "    x_df.drop(\"education\", inplace=True, axis=1)\n",
    "    x_df = x_df.join(education)\n",
    "    x_df[\"month\"] = x_df.month.map(months)\n",
    "    x_df[\"day_of_week\"] = x_df.day_of_week.map(weekdays)\n",
    "    x_df[\"poutcome\"] = x_df.poutcome.apply(lambda s: 1 if s == \"success\" else 0)\n",
    "\n",
    "    #y_df = x_df.pop(\"y\").apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "    return x_df\n",
    "    #return x_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# tryin to import this causes some weird ipykernel error...\n",
    "#from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "#x, y = clean_data(ds)\n",
    "# It makes no sense to split it to x and y in the clean data...\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cleaned_df = clean_data(ds)\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>marital</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>...</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>education_basic.4y</th>\n",
       "      <th>education_basic.6y</th>\n",
       "      <th>education_basic.9y</th>\n",
       "      <th>education_high.school</th>\n",
       "      <th>education_illiterate</th>\n",
       "      <th>education_professional.course</th>\n",
       "      <th>education_university.degree</th>\n",
       "      <th>education_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>285</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>355</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  marital  default  housing  loan  month  day_of_week  duration  \\\n",
       "0   57        1        0        0     1      5            1       371   \n",
       "1   55        1        0        1     0      5            4       285   \n",
       "2   33        1        0        0     0      5            5        52   \n",
       "3   36        1        0        0     0      6            5       355   \n",
       "4   27        1        0        1     0      7            5       189   \n",
       "\n",
       "   campaign  pdays  ...  contact_cellular  contact_telephone  \\\n",
       "0         1    999  ...                 1                  0   \n",
       "1         2    999  ...                 0                  1   \n",
       "2         1    999  ...                 1                  0   \n",
       "3         4    999  ...                 0                  1   \n",
       "4         2    999  ...                 1                  0   \n",
       "\n",
       "   education_basic.4y  education_basic.6y  education_basic.9y  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   1   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   education_high.school  education_illiterate education_professional.course  \\\n",
       "0                      1                     0                             0   \n",
       "1                      0                     0                             0   \n",
       "2                      0                     0                             0   \n",
       "3                      1                     0                             0   \n",
       "4                      1                     0                             0   \n",
       "\n",
       "   education_university.degree  education_unknown  \n",
       "0                            0                  0  \n",
       "1                            0                  1  \n",
       "2                            0                  0  \n",
       "3                            0                  0  \n",
       "4                            0                  0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1598275665403
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "\n",
    "# nowhere in the course I saw any instructions on what to fill in here so I'll\n",
    "# follow the microsoft documentation... I'm not should I use accuracy here as a metric or not\n",
    "\n",
    "# In the project instructions on 5. automl run it says to \"split data into train and valid tests\"\n",
    "# so I do that even though I would like to let the automl do its on cross-validation which\n",
    "# seems like a better idea\n",
    "\n",
    "# Note on the above, I can\\t even use the crossvalidation if I split the data\n",
    "# myself, yet another mistake in the project instructions. Anyway, I'll skip\n",
    "# splitting the data myself then...\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data= cleaned_df,\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Running on local machine. Note that local runs always run synchronously even if you use the parameter 'show_output=False'\n"
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "#from azureml.core.experiment import Experiment\n",
    "\n",
    "automl_experiment = Experiment(ws, 'automl_experiment2')\n",
    "automl_run = automl_experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score_macro 0.8024709413022642\n",
      "precision_score_micro 0.9162367223065251\n",
      "AUC_macro 0.9478183556341432\n",
      "recall_score_macro 0.7389831565343454\n",
      "weighted_accuracy 0.9602670741443091\n",
      "norm_macro_recall 0.47796631306869086\n",
      "f1_score_weighted 0.9113310776187307\n",
      "f1_score_micro 0.9162367223065251\n",
      "matthews_correlation 0.537508841672188\n",
      "average_precision_score_macro 0.8247844802527047\n",
      "AUC_micro 0.9807562789990814\n",
      "accuracy 0.9162367223065251\n",
      "balanced_accuracy 0.7389831565343454\n",
      "f1_score_macro 0.7652844325323995\n",
      "log_loss 0.19406776784049354\n",
      "recall_score_micro 0.9162367223065251\n",
      "average_precision_score_micro 0.9815786721005222\n",
      "average_precision_score_weighted 0.9555007096105637\n",
      "AUC_weighted 0.9478183556341431\n",
      "precision_score_weighted 0.9091819202578171\n",
      "recall_score_weighted 0.9162367223065251\n",
      "confusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_2726df91-1472-4473-9ace-0b0e30bc8f19_61/confusion_matrix\n",
      "accuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_2726df91-1472-4473-9ace-0b0e30bc8f19_61/accuracy_table\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "best_run, fitted_model = automl_run.get_output()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.to_csv('training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'TabularDatasetFactory' has no attribute 'get_by_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-255b4572a3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularDatasetFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'TabularDatasetFactory' has no attribute 'get_by_name'"
     ]
    }
   ],
   "source": [
    "#clean_ds = TabularDatasetFactory.get_by_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_temp_datastore\n",
      "workspaceblobstore\n",
      "workspacefilestore\n"
     ]
    }
   ],
   "source": [
    "#for ds_name in ws.datastores:\n",
    "#    print(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tab_dataset = Dataset.Tabular.from_delimited_files(path=(default_ds,'training_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./training_data.csv\n",
      "Uploaded ./training_data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_c4016d474917437aa06d0c3b301e4bf8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload_files(files=['./training_data.csv'], # Upload the diabetes csv files in /data\n",
    "                       target_path='training-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "blob_ds = ws.get_default_datastore()\n",
    "csv_paths = [(blob_ds, './training-data/training_data.csv')]\n",
    "tab_ds = Dataset.Tabular.from_delimited_files(path=csv_paths)\n",
    "tab_ds = tab_ds.register(workspace=ws, name='csv_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also running in the cloud compute target in case that was a requirement\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    task='classification',\n",
    "    primary_metric='accuracy',\n",
    "    training_data= tab_ds,\n",
    "    compute_target = training_cluster,\n",
    "    label_column_name='y',\n",
    "    n_cross_validations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote.\n"
     ]
    }
   ],
   "source": [
    "automl_experiment = Experiment(ws, 'automl_experiment3')\n",
    "automl_run = automl_experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_accuracy 0.7276485524057095\n",
      "norm_macro_recall 0.45529710481141905\n",
      "recall_score_macro 0.7276485524057095\n",
      "f1_score_micro 0.9143854324734446\n",
      "AUC_micro 0.9802809673920803\n",
      "weighted_accuracy 0.9607722394588862\n",
      "log_loss 0.17855504287929735\n",
      "precision_score_macro 0.7992603434698753\n",
      "accuracy 0.9143854324734446\n",
      "f1_score_macro 0.7564311285923817\n",
      "precision_score_micro 0.9143854324734446\n",
      "f1_score_weighted 0.9086173079094375\n",
      "matthews_correlation 0.5217934644908475\n",
      "average_precision_score_micro 0.9811264177399588\n",
      "average_precision_score_weighted 0.9545539983425243\n",
      "AUC_weighted 0.946096917302776\n",
      "precision_score_weighted 0.9063985559064617\n",
      "recall_score_micro 0.9143854324734446\n",
      "average_precision_score_macro 0.8213968176240831\n",
      "recall_score_weighted 0.9143854324734446\n",
      "AUC_macro 0.946096917302776\n",
      "confusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_5c4204b6-5881-49e9-abe4-01f73c9c1e68_1/confusion_matrix\n",
      "accuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_5c4204b6-5881-49e9-abe4-01f73c9c1e68_1/accuracy_table\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "best_run, fitted_model = automl_run.get_output()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipelineWithYTransformations(Pipeline={'memory': None,\n",
       "                                       'steps': [('datatransformer',\n",
       "                                                  DataTransformer(enable_dnn=None,\n",
       "                                                                  enable_feature_sweeping=None,\n",
       "                                                                  feature_sweeping_config=None,\n",
       "                                                                  feature_sweeping_timeout=None,\n",
       "                                                                  featurization_config=None,\n",
       "                                                                  force_text_dnn=None,\n",
       "                                                                  is_cross_validation=None,\n",
       "                                                                  is_onnx_compatible=None,\n",
       "                                                                  logger=None,\n",
       "                                                                  observer=None,\n",
       "                                                                  task=None,\n",
       "                                                                  working_dir=None))...\n",
       "                                                                    learning_rate=0.1,\n",
       "                                                                    max_delta_step=0,\n",
       "                                                                    max_depth=3,\n",
       "                                                                    min_child_weight=1,\n",
       "                                                                    missing=nan,\n",
       "                                                                    n_estimators=100,\n",
       "                                                                    n_jobs=1,\n",
       "                                                                    nthread=None,\n",
       "                                                                    objective='binary:logistic',\n",
       "                                                                    random_state=0,\n",
       "                                                                    reg_alpha=0,\n",
       "                                                                    reg_lambda=1,\n",
       "                                                                    scale_pos_weight=1,\n",
       "                                                                    seed=None,\n",
       "                                                                    silent=None,\n",
       "                                                                    subsample=1,\n",
       "                                                                    tree_method='auto',\n",
       "                                                                    verbose=-10,\n",
       "                                                                    verbosity=0))],\n",
       "                                       'verbose': False},\n",
       "                             y_transformer={},\n",
       "                             y_transformer_name='LabelEncoder')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
